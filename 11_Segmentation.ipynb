{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11-Segmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZvpqTF0CUDJ",
        "colab_type": "text"
      },
      "source": [
        "# Image segmentation\n",
        "\n",
        "In this notebook we will learn how to create an image segmentation model based on the U-Net neural network.\n",
        "\n",
        "![unet](https://github.com/jirimaterna/image-processing-2days/blob/master/images/unet.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eozEkbVmBie_",
        "colab_type": "text"
      },
      "source": [
        "Download data from the Git repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xl2miKSTyOP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1eaf82a2-6565-44b1-89b4-bfeee77047c7"
      },
      "source": [
        "!wget --output-document membrane.zip https://github.com/jirimaterna/image-processing-2days/blob/master/data/membrane.zip?raw=true\n",
        "#!wget --output-document unet_membrane.hdf5 https://github.com/jirimaterna/image-processing-2days/blob/master/models/unet_membrane.hdf5?raw=true\n",
        "!unzip membrane.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-22 10:10:35--  https://github.com/jirimaterna/image-processing-2days/blob/master/data/membrane.zip?raw=true\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/jirimaterna/image-processing-2days/raw/master/data/membrane.zip [following]\n",
            "--2019-07-22 10:10:36--  https://github.com/jirimaterna/image-processing-2days/raw/master/data/membrane.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/jirimaterna/image-processing-2days/master/data/membrane.zip [following]\n",
            "--2019-07-22 10:10:36--  https://media.githubusercontent.com/media/jirimaterna/image-processing-2days/master/data/membrane.zip\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14519885 (14M) [application/zip]\n",
            "Saving to: ‘membrane.zip’\n",
            "\n",
            "\rmembrane.zip          0%[                    ]       0  --.-KB/s               \rmembrane.zip        100%[===================>]  13.85M  84.1MB/s    in 0.2s    \n",
            "\n",
            "2019-07-22 10:10:37 (84.1 MB/s) - ‘membrane.zip’ saved [14519885/14519885]\n",
            "\n",
            "--2019-07-22 10:10:41--  https://github.com/jirimaterna/image-processing-2days/blob/master/models/unet_membrane.hdf5?raw=true\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/jirimaterna/image-processing-2days/raw/master/models/unet_membrane.hdf5 [following]\n",
            "--2019-07-22 10:10:41--  https://github.com/jirimaterna/image-processing-2days/raw/master/models/unet_membrane.hdf5\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/jirimaterna/image-processing-2days/master/models/unet_membrane.hdf5 [following]\n",
            "--2019-07-22 10:10:42--  https://raw.githubusercontent.com/jirimaterna/image-processing-2days/master/models/unet_membrane.hdf5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38866672 (37M) [application/octet-stream]\n",
            "Saving to: ‘unet_membrane.hdf5’\n",
            "\n",
            "unet_membrane.hdf5  100%[===================>]  37.07M   137MB/s    in 0.3s    \n",
            "\n",
            "2019-07-22 10:10:45 (137 MB/s) - ‘unet_membrane.hdf5’ saved [38866672/38866672]\n",
            "\n",
            "Archive:  membrane.zip\n",
            "replace membrane/test/17_predict.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: membrane/test/17_predict.png  \n",
            "replace membrane/test/25_predict.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: membrane/test/25_predict.png  \n",
            "  inflating: membrane/test/3_predict.png  \n",
            "  inflating: membrane/test/12_predict.png  \n",
            "  inflating: membrane/test/6_predict.png  \n",
            "  inflating: membrane/test/20_predict.png  \n",
            "  inflating: membrane/test/8.png     \n",
            "  inflating: membrane/test/29_predict.png  \n",
            "  inflating: membrane/test/9.png     \n",
            "  inflating: membrane/test/14.png    \n",
            "  inflating: membrane/test/28.png    \n",
            "  inflating: membrane/test/29.png    \n",
            "  inflating: membrane/test/15.png    \n",
            "  inflating: membrane/test/18_predict.png  \n",
            "  inflating: membrane/test/17.png    \n",
            "  inflating: membrane/test/23_predict.png  \n",
            "  inflating: membrane/test/5_predict.png  \n",
            "  inflating: membrane/test/11_predict.png  \n",
            "  inflating: membrane/test/16.png    \n",
            "  inflating: membrane/test/0_predict.png  \n",
            "  inflating: membrane/test/26_predict.png  \n",
            "  inflating: membrane/test/12.png    \n",
            "  inflating: membrane/test/14_predict.png  \n",
            "  inflating: membrane/test/13.png    \n",
            "  inflating: membrane/test/9_predict.png  \n",
            "  inflating: membrane/test/11.png    \n",
            "  inflating: membrane/test/10.png    \n",
            "  inflating: membrane/test/21.png    \n",
            "  inflating: membrane/test/28_predict.png  \n",
            "  inflating: membrane/test/20.png    \n",
            "  inflating: membrane/test/21_predict.png  \n",
            "  inflating: membrane/test/7_predict.png  \n",
            "  inflating: membrane/test/22.png    \n",
            "  inflating: membrane/test/13_predict.png  \n",
            "  inflating: membrane/test/23.png    \n",
            "  inflating: membrane/test/27.png    \n",
            "  inflating: membrane/test/2_predict.png  \n",
            "  inflating: membrane/test/24_predict.png  \n",
            "  inflating: membrane/test/26.png    \n",
            "  inflating: membrane/test/16_predict.png  \n",
            "  inflating: membrane/test/18.png    \n",
            "  inflating: membrane/test/24.png    \n",
            "  inflating: membrane/test/25.png    \n",
            "  inflating: membrane/test/19.png    \n",
            "  inflating: membrane/test/4.png     \n",
            "  inflating: membrane/test/8_predict.png  \n",
            "  inflating: membrane/test/5.png     \n",
            "  inflating: membrane/test/15_predict.png  \n",
            "  inflating: membrane/test/7.png     \n",
            "  inflating: membrane/test/27_predict.png  \n",
            "  inflating: membrane/test/1_predict.png  \n",
            "  inflating: membrane/test/6.png     \n",
            "  inflating: membrane/test/2.png     \n",
            "  inflating: membrane/test/10_predict.png  \n",
            "  inflating: membrane/test/3.png     \n",
            "  inflating: membrane/test/4_predict.png  \n",
            "  inflating: membrane/test/22_predict.png  \n",
            "  inflating: membrane/test/1.png     \n",
            "  inflating: membrane/test/19_predict.png  \n",
            "  inflating: membrane/test/0.png     \n",
            "  inflating: membrane/train/.DS_Store  \n",
            "  inflating: __MACOSX/membrane/train/._.DS_Store  \n",
            "  inflating: membrane/train/label/8.png  \n",
            "  inflating: membrane/train/label/9.png  \n",
            "  inflating: membrane/train/label/14.png  \n",
            "  inflating: membrane/train/label/28.png  \n",
            "  inflating: membrane/train/label/29.png  \n",
            "  inflating: membrane/train/label/15.png  \n",
            "  inflating: membrane/train/label/17.png  \n",
            "  inflating: membrane/train/label/16.png  \n",
            "  inflating: membrane/train/label/12.png  \n",
            "  inflating: membrane/train/label/13.png  \n",
            "  inflating: membrane/train/label/11.png  \n",
            "  inflating: membrane/train/label/10.png  \n",
            "  inflating: membrane/train/label/21.png  \n",
            "  inflating: membrane/train/label/20.png  \n",
            "  inflating: membrane/train/label/22.png  \n",
            "  inflating: membrane/train/label/23.png  \n",
            "  inflating: membrane/train/label/27.png  \n",
            "  inflating: membrane/train/label/26.png  \n",
            "  inflating: membrane/train/label/18.png  \n",
            "  inflating: membrane/train/label/24.png  \n",
            "  inflating: membrane/train/label/25.png  \n",
            "  inflating: membrane/train/label/19.png  \n",
            "  inflating: membrane/train/label/4.png  \n",
            "  inflating: membrane/train/label/5.png  \n",
            "  inflating: membrane/train/label/7.png  \n",
            "  inflating: membrane/train/label/6.png  \n",
            "  inflating: membrane/train/label/2.png  \n",
            "  inflating: membrane/train/label/3.png  \n",
            "  inflating: membrane/train/label/1.png  \n",
            "  inflating: membrane/train/label/0.png  \n",
            "  inflating: membrane/train/image/8.png  \n",
            "  inflating: membrane/train/image/9.png  \n",
            "  inflating: membrane/train/image/14.png  \n",
            "  inflating: membrane/train/image/28.png  \n",
            "  inflating: membrane/train/image/29.png  \n",
            "  inflating: membrane/train/image/15.png  \n",
            "  inflating: membrane/train/image/17.png  \n",
            "  inflating: membrane/train/image/16.png  \n",
            "  inflating: membrane/train/image/12.png  \n",
            "  inflating: membrane/train/image/13.png  \n",
            "  inflating: membrane/train/image/11.png  \n",
            "  inflating: membrane/train/image/10.png  \n",
            "  inflating: membrane/train/image/21.png  \n",
            "  inflating: membrane/train/image/20.png  \n",
            "  inflating: membrane/train/image/22.png  \n",
            "  inflating: membrane/train/image/23.png  \n",
            "  inflating: membrane/train/image/27.png  \n",
            "  inflating: membrane/train/image/26.png  \n",
            "  inflating: membrane/train/image/18.png  \n",
            "  inflating: membrane/train/image/24.png  \n",
            "  inflating: membrane/train/image/25.png  \n",
            "  inflating: membrane/train/image/19.png  \n",
            "  inflating: membrane/train/image/4.png  \n",
            "  inflating: membrane/train/image/5.png  \n",
            "  inflating: membrane/train/image/7.png  \n",
            "  inflating: membrane/train/image/6.png  \n",
            "  inflating: membrane/train/image/2.png  \n",
            "  inflating: membrane/train/image/3.png  \n",
            "  inflating: membrane/train/image/1.png  \n",
            "  inflating: membrane/train/image/0.png  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1g5HxDMGwah",
        "colab_type": "text"
      },
      "source": [
        "Data preparation rutines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuLpvT9ic0tf",
        "colab_type": "code",
        "outputId": "271af551-b327-464b-8048-ffc24c0e16dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np \n",
        "import os\n",
        "import glob\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "\n",
        "\n",
        "\n",
        "def adjustData(img,mask,flag_multi_class,num_class):\n",
        "    if(flag_multi_class):\n",
        "        img = img / 255\n",
        "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
        "        new_mask = np.zeros(mask.shape + (num_class,))\n",
        "        for i in range(num_class):\n",
        "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
        "            #index = np.where(mask == i)\n",
        "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
        "            #new_mask[index_mask] = 1\n",
        "            new_mask[mask == i,i] = 1\n",
        "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
        "        mask = new_mask\n",
        "    elif(np.max(img) > 1):\n",
        "        img = img / 255\n",
        "        mask = mask /255\n",
        "        mask[mask > 0.5] = 1\n",
        "        mask[mask <= 0.5] = 0\n",
        "    return (img,mask)\n",
        "  \n",
        "def testGenerator(test_path,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = True):\n",
        "    for i in range(num_image):\n",
        "        img = io.imread(os.path.join(test_path,\"%d.png\"%i),as_gray = as_gray)\n",
        "        img = img / 255\n",
        "        img = trans.resize(img,target_size)\n",
        "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
        "        img = np.reshape(img,(1,)+img.shape)\n",
        "        yield img\n",
        "        \n",
        "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
        "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
        "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
        "    '''\n",
        "    can generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
        "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "    '''\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [image_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed)\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [mask_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed)\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img,mask) in train_generator:\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        yield (img,mask)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dws-jNKbG3R9",
        "colab_type": "text"
      },
      "source": [
        "Unet model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1vmZoDHWNoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "b62d3a36-6a1a-4fdd-fcd1-7f61726ff756"
      },
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "\n",
        "inputs = Input((256,256,1))\n",
        "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "drop4 = Dropout(0.5)(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "merge6 = concatenate([drop4,up6],axis = 3)\n",
        "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "merge7 = concatenate([conv3,up7], axis = 3)\n",
        "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "merge8 = concatenate([conv2,up8], axis = 3)\n",
        "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "merge9 = concatenate([conv1,up9], axis = 3)\n",
        "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "model = Model(inputs = inputs, outputs = conv10)\n",
        "\n",
        "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "\n",
        "#model.load_weights('unet_membrane.hdf5')\n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e09e4fb5d9c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unet_membrane.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (truncated file: eof = 38866672, sblock->base_addr = 0, stored_eof = 372551468)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ApZRExHHDSt",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-N4VAx4atyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGene = trainGenerator(2,'membrane/train','image','label',data_gen_args,save_to_dir = None)\n",
        "model.fit_generator(myGene,steps_per_epoch=2000,epochs=10,callbacks=[model_checkpoint])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Il2CujOK64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('unet_membrane.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_lHz048Jjoj",
        "colab_type": "text"
      },
      "source": [
        "Predict on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OGAG8t4HqvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def labelVisualize(num_class,color_dict,img):\n",
        "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
        "    img_out = np.zeros(img.shape + (3,))\n",
        "    for i in range(num_class):\n",
        "        img_out[img == i,:] = color_dict[i]\n",
        "    return img_out / 255\n",
        "\n",
        "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
        "    for i,item in enumerate(npyfile):\n",
        "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
        "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
        "\n",
        "testGene = testGenerator(\"membrane/test\")\n",
        "results = model.predict_generator(testGene,30,verbose=1)\n",
        "saveResult(\"membrane/test\",results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EczuIeWcZ6l7",
        "colab_type": "text"
      },
      "source": [
        "Visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHvnmv5QN_gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image('membrane/test/0.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXDzPSYIgcfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('membrane/test/0_predict.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXZBg_6cKFg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8248c4a0-fb75-4f27-8c88-6fc567197056"
      },
      "source": [
        "!ls membrane/test/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.png\t12.png\t15.png\t18.png\t20.png\t23.png\t26.png\t29.png\t4.png  7.png\n",
            "10.png\t13.png\t16.png\t19.png\t21.png\t24.png\t27.png\t2.png\t5.png  8.png\n",
            "11.png\t14.png\t17.png\t1.png\t22.png\t25.png\t28.png\t3.png\t6.png  9.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48kF5S6UKGRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}