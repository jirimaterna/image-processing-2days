{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Keras\n",
    "\n",
    "* high-level neural networks API, written in Python and capable of running on top of [TensorFlow](https://github.com/tensorflow/tensorflow), [CNTK](https://github.com/Microsoft/cntk), or [Theano](https://github.com/Theano/Theano)\n",
    "* Allows easy and fast prototyping\n",
    "* Runs seamlessly on CPU and GPU\n",
    "* open source\n",
    "* Documentation: [https://keras.io/](https://keras.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installation\n",
    "First install the backend, for example [TensorFlow](https://www.tensorflow.org/install/).\n",
    "\n",
    "`$ pip install keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST classification task\n",
    "\n",
    "The MNIST data set is a database of handwritten digits that is commonly used for training various image processing systems. The goal if this task is to implement a classifier of handwritten digits using neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mnist data set](images/mnist-examples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "The data is already shuffled and split to train and test parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train original shape: (60000, 28, 28)\n",
      "y_train original shape: (60000,)\n",
      "X_test original shape: (10000, 28, 28)\n",
      "y_test original shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"X_train original shape: {}\".format(X_train.shape))\n",
    "print(\"y_train original shape: {}\".format(y_train.shape))\n",
    "print(\"X_test original shape: {}\".format(X_test.shape))\n",
    "print(\"y_test original shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at one random example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "i=3495\n",
    "\n",
    "#print(X_train[i])\n",
    "plt.imshow(X_train[i], cmap='gray')\n",
    "plt.title(\"Class {}\".format(y_train[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scale the input values to have the range (0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural-network is going to take a single vector for each training example, so we need to reshape the input so that each 28x28 image becomes a single 784 dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train matrix shape: (60000, 784)\n",
      "X_test matrix shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_flat = X_train.reshape(60000, 784)\n",
    "X_test_flat = X_test.reshape(10000, 784)\n",
    "print(\"X_train matrix shape: {}\".format(X_train_flat.shape))\n",
    "print(\"X_test matrix shape: {}\".format(X_test_flat.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the targets into one-hot encoding, i.e.\n",
    "```\n",
    "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "```\n",
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "n_classes = 10\n",
    "\n",
    "print(y_train[49])\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print(y_train[49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of one-layer classifier for MNIST\n",
    "\n",
    "![Mnist data set](images/one-layer-nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture definition\n",
    "\n",
    "Create a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model.add(Dense(64, input_shape=(784, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0942 - acc: 0.9729 - val_loss: 0.1030 - val_acc: 0.9682\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0826 - acc: 0.9762 - val_loss: 0.1020 - val_acc: 0.9697\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0737 - acc: 0.9784 - val_loss: 0.0989 - val_acc: 0.9694\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0658 - acc: 0.9805 - val_loss: 0.0923 - val_acc: 0.9707\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0593 - acc: 0.9829 - val_loss: 0.0881 - val_acc: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda0daf3780>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_flat, y_train,\n",
    "          batch_size = 128, epochs = 5, verbose=1,\n",
    "          validation_data=(X_test_flat, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "First we need to convert probability vectors to class indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_flat)\n",
    "\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "print(y_pred_class.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the scikit-learn functions now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9720\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9710    0.9898    0.9803       980\n",
      "          1     0.9825    0.9877    0.9851      1135\n",
      "          2     0.9646    0.9777    0.9711      1032\n",
      "          3     0.9647    0.9733    0.9690      1010\n",
      "          4     0.9696    0.9756    0.9726       982\n",
      "          5     0.9783    0.9596    0.9689       892\n",
      "          6     0.9749    0.9718    0.9733       958\n",
      "          7     0.9782    0.9611    0.9696      1028\n",
      "          8     0.9709    0.9579    0.9643       974\n",
      "          9     0.9652    0.9623    0.9638      1009\n",
      "\n",
      "avg / total     0.9720    0.9720    0.9720     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "print (\"Test accuracy: {:.4f}\".format(accuracy_score(y_test_class, y_pred_class)))\n",
    "print ()\n",
    "print(metrics.classification_report(y_test_class, y_pred_class, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 962    0    1    1    0    4    9    1    1    1]\n",
      " [   0 1121    4    0    0    1    5    1    3    0]\n",
      " [   5    3  995    5    3    1    4    7    7    2]\n",
      " [   0    1    6  972    0    7    1   10    9    4]\n",
      " [   1    0    3    0  949    0   13    1    2   13]\n",
      " [   5    1    0   11    2  854   10    1    5    3]\n",
      " [   5    3    1    0    4    4  940    0    1    0]\n",
      " [   0    7    8    2    0    1    0  993    1   16]\n",
      " [   4    2    4   14    7    9   11    4  910    9]\n",
      " [   3    6    1   11   21    1    1    6    1  958]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9875    0.9868    0.9872      5923\n",
      "          1     0.9731    0.9920    0.9824      6742\n",
      "          2     0.9822    0.9730    0.9776      5958\n",
      "          3     0.9758    0.9605    0.9681      6131\n",
      "          4     0.9722    0.9750    0.9736      5842\n",
      "          5     0.9759    0.9646    0.9702      5421\n",
      "          6     0.9636    0.9941    0.9786      5918\n",
      "          7     0.9832    0.9730    0.9781      6265\n",
      "          8     0.9720    0.9501    0.9609      5851\n",
      "          9     0.9549    0.9679    0.9613      5949\n",
      "\n",
      "avg / total     0.9741    0.9740    0.9740     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train_flat)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "y_train_class = np.argmax(y_train, axis=1)\n",
    "\n",
    "print (\"Train accuracy: {:.4f}\".format(accuracy_score(y_train_class, y_pred_class)))\n",
    "print ()\n",
    "print(metrics.classification_report(y_train_class, y_pred_class, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network for MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3d = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test3d = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture definition\n",
    "\n",
    "Create a sequential model and define its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 16)        416       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12, 12, 32)        544       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                46090     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 47,050\n",
      "Trainable params: 47,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dense(32))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.3453 - acc: 0.8988 - val_loss: 0.1051 - val_acc: 0.9693\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.1085 - acc: 0.9673 - val_loss: 0.0650 - val_acc: 0.9806\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 24s 395us/step - loss: 0.0832 - acc: 0.9744 - val_loss: 0.0517 - val_acc: 0.9834\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 23s 389us/step - loss: 0.0703 - acc: 0.9790 - val_loss: 0.0463 - val_acc: 0.9849\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 0.0613 - acc: 0.9811 - val_loss: 0.0424 - val_acc: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda24294240>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train3d, y_train,\n",
    "          batch_size = 128, epochs = 5, verbose=1,\n",
    "          validation_data=(X_test3d, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test3d)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9862\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9848    0.9929    0.9888       980\n",
      "          1     0.9912    0.9947    0.9930      1135\n",
      "          2     0.9834    0.9748    0.9791      1032\n",
      "          3     0.9757    0.9931    0.9843      1010\n",
      "          4     0.9888    0.9929    0.9909       982\n",
      "          5     0.9887    0.9832    0.9859       892\n",
      "          6     0.9968    0.9791    0.9879       958\n",
      "          7     0.9797    0.9874    0.9835      1028\n",
      "          8     0.9836    0.9836    0.9836       974\n",
      "          9     0.9900    0.9792    0.9846      1009\n",
      "\n",
      "avg / total     0.9862    0.9862    0.9862     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Test accuracy: {:.4f}\".format(accuracy_score(y_test_class, y_pred_class)))\n",
    "print ()\n",
    "print(metrics.classification_report(y_test_class, y_pred_class, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c64f0c71b977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train3d)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "y_train_class = np.argmax(y_train, axis=1)\n",
    "\n",
    "print (\"Train accuracy: {:.4f}\".format(accuracy_score(y_train_class, y_pred_class)))\n",
    "print ()\n",
    "print(metrics.classification_report(y_train_class, y_pred_class, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at some incorrectly classified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 149  259  321  340  582  659  674  684  717  720  740  844  924  947\n",
      " 1014 1039 1181 1182 1226 1232 1242 1247 1319 1326 1393 1527 1530 1609\n",
      " 1621 1709 1722 1737 1754 1878 1901 2035 2043 2098 2109 2118 2130 2135\n",
      " 2182 2189 2266 2293 2369 2387 2406 2447 2454 2462 2597 2635 2654 2760\n",
      " 2780 2810 2896 2921 2927 2939 2995 3030 3060 3073 3206 3289 3330 3422\n",
      " 3503 3511 3520 3597 3599 3727 3751 3767 3808 3811 3853 3869 3906 4065\n",
      " 4075 4176 4224 4238 4248 4256 4350 4360 4536 4547 4571 4575 4639 4740\n",
      " 4761 4807 4814 4880 4956 4997 5634 5877 5888 5937 5955 5973 5981 6091\n",
      " 6505 6571 6572 6576 6597 6625 6651 6847 7492 8059 8094 8311 8408 9009\n",
      " 9015 9024 9634 9642 9664 9692 9729 9770 9811 9839 9904 9982]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test3d)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "incorrect_indices = np.nonzero(y_pred_class != y_test_class)[0]\n",
    "print(incorrect_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "i = incorrect_indices[3]\n",
    "\n",
    "plt.imshow(X_test[i], cmap='gray')\n",
    "plt.title(\"Predicted: {}, Class: {}\".format(y_pred_class[i], y_test_class[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
